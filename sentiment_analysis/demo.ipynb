{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import project1 as p1\n",
    "import utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and Explore data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = utils.load_data('reviews_train.tsv')\n",
    "val_data = utils.load_data('reviews_val.tsv')\n",
    "test_data = utils.load_data('reviews_test.tsv')\n",
    "\n",
    "train_texts, train_labels = zip(*((sample['text'], sample['sentiment']) for sample in train_data))\n",
    "val_texts, val_labels = zip(*((sample['text'], sample['sentiment']) for sample in val_data))\n",
    "test_texts, test_labels = zip(*((sample['text'], sample['sentiment']) for sample in test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE 1:\n",
      "review: The chips are okay Not near as flavorful as the regular blue chips. Nice size bag for a family.,\n",
      "label: -1\n",
      "\n",
      "\n",
      "SAMPLE 2:\n",
      "review: I had high hopes for this, but it was bad.  Really bad.  The whole pan of cupcakes made from this had to be thrown out.  Very gritty and dense.,\n",
      "label: -1\n",
      "\n",
      "\n",
      "SAMPLE 3:\n",
      "review: I guess it's only one can since there is nothing in the description about how many cans you get. I guess we can't all be intelligent.,\n",
      "label: -1\n",
      "\n",
      "\n",
      "SAMPLE 4:\n",
      "review: \"Oatmeal Squares\" is in about the largest print you can fit on the Front of the Box.  When you read the ingredients, the second largest ingredient is WHEAT flour. So how can it rightfully be called a \"Crunchy Oat Cereal\".<br /><br />I wonder why Quaker, which is noted for Oatmeal has to be somewhat deceptive and not disclose upfront that this is not completely an Oat Cereal and then go on to make claims about Cholesterol Lowering when it is not ALL Oat Flour.<br /><br />Oatmeal is made from oats not wheat.  This is really \"Oatmeal and Wheat Squares\"<br /><br />Who cares how it tastes if it is not what it says it is.,\n",
      "label: -1\n",
      "\n",
      "\n",
      "SAMPLE 5:\n",
      "review: I really enjoyed this flavor, this has a very nice subtle coconut flavor that is not too sweet.  It's a hit in our household, I give them to my grand kids every time they come over and needless to say they keep coming back!,\n",
      "label: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Take a view at our data\n",
    "#Print the first 5 review and its label\n",
    "for i in range(5):\n",
    "    print(f'SAMPLE {i+1}:\\nreview: {train_texts[i]},\\nlabel: {train_labels[i]}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Transform data into the form suitable for perceptron algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more infor on how `bag_of_words` and `extract_bow_feature_vectors` work, see project.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = p1.bag_of_words(train_texts,remove_stopword=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LENGTH OF THE DICT:  13108\n",
      "\n",
      "\n",
      "FIRST 5 ITEMS\n",
      "Word: chips, Idx: 0\n",
      "Word: okay, Idx: 1\n",
      "Word: near, Idx: 2\n",
      "Word: flavorful, Idx: 3\n",
      "Word: regular, Idx: 4\n"
     ]
    }
   ],
   "source": [
    "# a dictionary that maps each word appearing in corpus of text to a unique integer `index`. In here, the corpus of text is our train_texts\n",
    "print('LENGTH OF THE DICT: ', len(dictionary))\n",
    "\n",
    "# Print the first 10 items in the dictonary\n",
    "print('\\n')\n",
    "print('FIRST 5 ITEMS')\n",
    "count=0\n",
    "for word,idx in dictionary.items():\n",
    "    if count==5:\n",
    "        break\n",
    "    count+=1\n",
    "    print(\"Word: {}, Idx: {}\".format(word,idx))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using dictionary to convert each sample in train_texts to 1-d array,each of length of the dictionary used (13108).<br>\n",
    "`extract_bow_feature_vectors` provides 2 modes: <br>\n",
    "(a) binary=True: i^th entry of the train_bow_features sample is:\n",
    "* 1 of the train sentence contain corrensponding word ith in dictionary; \n",
    "* 0 otherwise <br>\n",
    "(b) binary=False: i^th entry of the train_bow_features sample is the number of times the corresponding word occurs in the train sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODE 1: binary=False\n",
    "train_bow_features = p1.extract_bow_feature_vectors(train_texts, dictionary,binarize=False)\n",
    "val_bow_features = p1.extract_bow_feature_vectors(val_texts, dictionary,binarize=False)\n",
    "test_bow_features = p1.extract_bow_feature_vectors(test_texts, dictionary,binarize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODE 2: binary=True\n",
    "train_bow_features_bi = p1.extract_bow_feature_vectors(train_texts, dictionary,binarize=True)\n",
    "val_bow_features_bi = p1.extract_bow_feature_vectors(val_texts, dictionary,binarize=True)\n",
    "test_bow_features_bi = p1.extract_bow_feature_vectors(test_texts, dictionary,binarize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE OF TRAIN_BOW_FEATURES:  (4000, 13108)\n",
      "NUMBER OF SAMPLE:  4000\n",
      "DIMENSION OF A TRAIN DATA:  13108\n"
     ]
    }
   ],
   "source": [
    "print('SHAPE OF TRAIN_BOW_FEATURES: ', train_bow_features.shape)\n",
    "print('NUMBER OF SAMPLE: ', train_bow_features.shape[0])\n",
    "print('DIMENSION OF A TRAIN DATA: ', train_bow_features.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Use 3 different variations of perceptron algorith for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use 3 type of perceptron algorithm to classify sentiments.\n",
    "1. Vanilla perceptron algorithm\n",
    "2. Average perceptron algorithm\n",
    "3. Pegasos perceptron algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODE 1: binarize=False\n",
      "Training accuracy for perceptron:   0.7953\n",
      "Validation accuracy for perceptron: 0.6900\n",
      "Training accuracy for average perceptron:   0.9030\n",
      "Validation accuracy for average perceptron: 0.7520\n",
      "Training accuracy for Pegasos:                     0.8592\n",
      "Validation accuracy for Pegasos:                   0.7480\n"
     ]
    }
   ],
   "source": [
    "# Set some hyperparameters needed for training\n",
    "\n",
    "T = 10\n",
    "L = 0.01\n",
    "print('MODE 1: binarize=False')\n",
    "pct_train_accuracy, pct_val_accuracy = \\\n",
    "   p1.classifier_accuracy(p1.perceptron, train_bow_features,val_bow_features,train_labels,val_labels,T=T)\n",
    "print(\"{:35} {:.4f}\".format(\"Training accuracy for perceptron:\", pct_train_accuracy))\n",
    "print(\"{:35} {:.4f}\".format(\"Validation accuracy for perceptron:\", pct_val_accuracy))\n",
    "\n",
    "avg_pct_train_accuracy, avg_pct_val_accuracy = \\\n",
    "   p1.classifier_accuracy(p1.average_perceptron, train_bow_features,val_bow_features,train_labels,val_labels,T=T)\n",
    "print(\"{:43} {:.4f}\".format(\"Training accuracy for average perceptron:\", avg_pct_train_accuracy))\n",
    "print(\"{:43} {:.4f}\".format(\"Validation accuracy for average perceptron:\", avg_pct_val_accuracy))\n",
    "\n",
    "avg_peg_train_accuracy, avg_peg_val_accuracy = \\\n",
    "   p1.classifier_accuracy(p1.pegasos, train_bow_features,val_bow_features,train_labels,val_labels,T=T,L=L)\n",
    "print(\"{:50} {:.4f}\".format(\"Training accuracy for Pegasos:\", avg_peg_train_accuracy))\n",
    "print(\"{:50} {:.4f}\".format(\"Validation accuracy for Pegasos:\", avg_peg_val_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODE 1: BINARIZE=True\n",
      "Training accuracy for perceptron:   0.9832\n",
      "Validation accuracy for perceptron: 0.7600\n",
      "Training accuracy for average perceptron:   0.9868\n",
      "Validation accuracy for average perceptron: 0.7760\n",
      "Training accuracy for Pegasos:                     0.9123\n",
      "Validation accuracy for Pegasos:                   0.7860\n"
     ]
    }
   ],
   "source": [
    "print('MODE 1: BINARIZE=True')\n",
    "pct_train_accuracy, pct_val_accuracy = \\\n",
    "   p1.classifier_accuracy(p1.perceptron, train_bow_features_bi,val_bow_features_bi,train_labels,val_labels,T=T)\n",
    "print(\"{:35} {:.4f}\".format(\"Training accuracy for perceptron:\", pct_train_accuracy))\n",
    "print(\"{:35} {:.4f}\".format(\"Validation accuracy for perceptron:\", pct_val_accuracy))\n",
    "\n",
    "avg_pct_train_accuracy, avg_pct_val_accuracy = \\\n",
    "   p1.classifier_accuracy(p1.average_perceptron, train_bow_features_bi,val_bow_features_bi,train_labels,val_labels,T=T)\n",
    "print(\"{:43} {:.4f}\".format(\"Training accuracy for average perceptron:\", avg_pct_train_accuracy))\n",
    "print(\"{:43} {:.4f}\".format(\"Validation accuracy for average perceptron:\", avg_pct_val_accuracy))\n",
    "\n",
    "avg_peg_train_accuracy, avg_peg_val_accuracy = \\\n",
    "   p1.classifier_accuracy(p1.pegasos, train_bow_features_bi,val_bow_features_bi,train_labels,val_labels,T=T,L=L)\n",
    "print(\"{:50} {:.4f}\".format(\"Training accuracy for Pegasos:\", avg_peg_train_accuracy))\n",
    "print(\"{:50} {:.4f}\".format(\"Validation accuracy for Pegasos:\", avg_peg_val_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Testing the performance of the model with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_theta=p1.pegasos(train_bow_features_bi,train_labels,T=T,L=L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE OF PREDICTION ON TRAINING DATA:  (500,)\n"
     ]
    }
   ],
   "source": [
    "sent_pred=p1.classify(test_bow_features_bi,best_theta[0],best_theta[1])\n",
    "print('SHAPE OF PREDICTION ON TRAINING DATA: ',sent_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE 6\n",
      "Review:  After doing numerous googles looking for Chipsters, one of my favorite childhood snacks, some reported that this product was very close to them. I disagree. About the closest flavor to the Chipsters so far would be Munchos, but still not the same. If you are conscious of diet, these will probably due.\n",
      "Predicted sentiment:  -1\n",
      "Real sentiment:  -1\n",
      "\n",
      "\n",
      "SAMPLE 7\n",
      "Review:  The texture of this chip is firm, solid, substantial, and minimally crispy. The taste is rich with favors of different seeds and grains. It seems that the inclusion of sesame seeds, in particular, makes this chip especially aromatic and pleasing to the taste.\n",
      "Predicted sentiment:  -1\n",
      "Real sentiment:  1\n",
      "\n",
      "\n",
      "SAMPLE 8\n",
      "Review:  I'm drinking oolong tea because Dr Oz said it would raise metabolism, the jury is still out.......really how would you know? I have lost weight but that's because I quit drinking coffee which I added too much cream to and started working out a lot more. It does not taste the all that great so I add 3 equals and drink it after it cools.\n",
      "Predicted sentiment:  -1\n",
      "Real sentiment:  -1\n",
      "\n",
      "\n",
      "SAMPLE 9\n",
      "Review:  This dip mix is too salty, and it tastes more like onions than anything. You can achieve the same results from a package of onion soup mix and some sour cream..... I used it once, and the rest of the container is sitting in my cupboard. Don't bother.\n",
      "Predicted sentiment:  -1\n",
      "Real sentiment:  -1\n",
      "\n",
      "\n",
      "SAMPLE 10\n",
      "Review:  I love this amazing product.  I eat it daily in coffee yogurt or in natural vanilla yogurt.  I love the crunch with a bit of chocolate.  I am fortunate that I do no have to order this item online here.  I can find it MUCH cheaper at my local grocery and then sometimes even cheaper when on a B1G1 sale.  Anyway, I love the product!\n",
      "Predicted sentiment:  1\n",
      "Real sentiment:  1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print 5 test sentence, its pred label and real label\n",
    "\n",
    "for i in range(5,10):\n",
    "    print(f'SAMPLE {i+1}')\n",
    "    print('Review: ',test_texts[i])\n",
    "    print('Predicted sentiment: ',sent_pred[i])\n",
    "    print('Real sentiment: ',test_labels[i])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Find the most explanatory words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Explanatory Word Features\n",
      "['great', 'delicious', 'loves', '!', 'best', 'excellent', 'perfect', 'wonderful', 'favorite', 'tasty']\n"
     ]
    }
   ],
   "source": [
    "wordlist   = [word for (idx, word) in sorted(zip(dictionary.values(), dictionary.keys()))]\n",
    "sorted_word_features = utils.most_explanatory_word(best_theta[0], wordlist)\n",
    "print(\"Most Positive Explanatory Word Features\")\n",
    "print(sorted_word_features[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Negative Explanatory Word Features\n",
      "['disappointed', 'bad', 'however', 'ok', '?', 'disappointment', 'thought', 'unfortunately', 'stale', 'fine']\n"
     ]
    }
   ],
   "source": [
    "print(\"Most Negative Explanatory Word Features\")\n",
    "print(sorted_word_features[-10:][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
